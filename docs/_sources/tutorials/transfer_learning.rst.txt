

.. _sphx_glr_tutorials_transfer_learning.py:


Transfer Learning Tutorial
==========================

In this tutorial, you will learn how to train your network using
transfer learning. You can read more about transfer learning at `cs231
notes <http://cs231n.github.io/transfer-learning/>`__

Quoting this notes,

    In practice, very few people train an entire Convolutional Network
    from scratch (with random initialization), because it is relatively
    rare to have a dataset of sufficient size. Instead, it is common to
    pretrain a ConvNet on a very large dataset (e.g. ImageNet, which
    contains 1.2 million images with 1000 categories), and then use the
    ConvNet either as an initialization or a fixed feature extractor for
    the task of interest.

Two major ways transfer learning scenarios looks as follows:

-  **Finetuning the convnet**: Instead of random initializaion, we
   initialize the network with a pretrained network, like the one that is
   trained on imagenet 1000 dataset. Rest of the training looks as
   usual.
-  **ConvNet as fixed feature extractor**: Here, we will freeze weights
   for all of the network except that of the final fully connected
   layer. This last fully connected layer is replaced with a new one
   with random weights and only this layer is modified.




.. code-block:: python


    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.autograd import Variable
    import numpy as np
    import torchvision
    from torchvision import datasets, models, transforms
    import matplotlib.pyplot as plt
    import time
    import copy
    import os


Load Data
---------

We will use torchvision and torch.utils.data packages for loading the
data.

The problem we're going to solve today is to train a model to classify
ants and bees. We have about 120 training images each for ants and bees.
There are 75 validation images for each class. Usually, this is a very
small dataset to generalize up on if trained from scratch. But since we
are use transfer learning, we should be able to generalize reasonably
well.

This dataset is a very small subset of imagenet. Download the data from
`here <https://github.com/chsasank/pytorch-tutorials/raw/master/tutorial_source/hymenoptera_data.zip>`_
and extract it to the current directory.



.. code-block:: python


    data_transforms = {
        'train': transforms.Compose([
            transforms.RandomSizedCrop(224),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
        'val': transforms.Compose([
            transforms.Scale(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }

    data_dir = 'hymenoptera_data'
    dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])
             for x in ['train', 'val']}
    dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=4,
                                                   shuffle=True, num_workers=4)
                    for x in ['train', 'val']}
    dset_sizes = {x: len(dsets[x]) for x in ['train', 'val']}
    dset_classes = dsets['train'].classes

    use_gpu = torch.cuda.is_available()



Visualize a few images
^^^^^^^^^^^^^^^^^^^^^^




.. code-block:: python


    def imshow(inp):
        """Imshow for Tensor."""
        inp = inp.numpy().transpose((1, 2, 0))
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        inp = std * inp + mean
        plt.imshow(inp)


    # Get a batch of data
    inputs, classes = next(iter(dset_loaders['train']))

    # Make a grid from batch
    out = torchvision.utils.make_grid(inputs)

    imshow(out)
    plt.title([dset_classes[x] for x in classes])
    plt.show()



Training the model
------------------

Now, let's write a general function to train a model. We will also
illustrate:

-  Scheduling of learning rate
-  Saving(deep copying) the best model

Here, ``optim_scheduler`` is a function which returns an ``optim.SGD``
object when called as ``optim_scheduler(model, epoch)``. This is useful
when we want to change the learning rate or restrict the parameters we
want to optimize.




.. code-block:: python


    def train_model(model, criterion, optim_scheduler, num_epochs=25):
        since = time.time()

        best_model = model
        best_acc = 0.0

        for epoch in range(num_epochs):
            print('Epoch {}/{}'.format(epoch, num_epochs - 1))
            print('-' * 10)

            # Each epoch has a training and validation phase
            for phase in ['train', 'val']:
                if phase == 'train':
                    optimizer = optim_scheduler(model, epoch)

                running_loss = 0.0
                running_corrects = 0

                # Iterate over data.
                for data in dset_loaders[phase]:
                    # get the inputs
                    inputs, labels = data

                    # wrap them in Variable
                    if use_gpu:
                        inputs, labels = Variable(inputs.cuda()), \
                            Variable(labels.cuda())
                    else:
                        inputs, labels = Variable(inputs), Variable(labels)

                    # zero the parameter gradients
                    optimizer.zero_grad()

                    # forward
                    outputs = model(inputs)
                    _, preds = torch.max(outputs.data, 1)
                    loss = criterion(outputs, labels)

                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                    # statistics
                    running_loss += loss.data[0]
                    running_corrects += torch.sum(preds == labels.data)

                epoch_loss = running_loss / dset_sizes[phase]
                epoch_acc = running_corrects / dset_sizes[phase]

                print('{} Loss: {:.4f} Acc: {:.4f}'.format(
                    phase, epoch_loss, epoch_acc))

                # deep copy the model
                if phase == 'val' and epoch_acc > best_acc:
                    best_acc = epoch_acc
                    best_model = copy.deepcopy(model)

            print()

        time_elapsed = time.time() - since
        print('Training complete in {:.0f}m {:.0f}s'.format(
            time_elapsed // 60, time_elapsed % 60))
        print('Best val Acc: {:4f}'.format(best_acc))
        return best_model



Visualizing the model predictions
---------------------------------

Generic function to display predictions for a few images




.. code-block:: python


    def evaluate_model(model, num_images=5):
        for i, data in enumerate(dset_loaders['val']):
            inputs, labels = data
            if use_gpu:
                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())
            else:
                inputs, labels = Variable(inputs), Variable(labels)

            # forward + backward + optimize
            outputs = model(inputs)
            _, preds = torch.max(outputs.data, 1)

            imshow(inputs.cpu().data[0])
            plt.title('pred: {}'.format(dset_classes[labels.data[0]]))
            plt.show()

            if i == num_images - 1:
                break



Finetuning the convnet
----------------------

First, let's create our learning rate scheduler. We will exponentially
decrease the learning rate every few epochs.




.. code-block:: python


    def optim_scheduler_ft(model, epoch, init_lr=0.001, lr_decay_epoch=7):
        lr = init_lr * (0.1**(epoch // lr_decay_epoch))

        if epoch % lr_decay_epoch == 0:
            print('LR is set to {}'.format(lr))

        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)
        return optimizer



Load a pretrained model and reset final fully connected layer.




.. code-block:: python


    model = models.resnet18(pretrained=True)
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, 2)

    if use_gpu:
        model = model.cuda()

    criterion = nn.CrossEntropyLoss()



Train and evaluate:

It should take around 15-25 min on CPU. On GPU though, it just takes around
5 min.




.. code-block:: python


    model = train_model(model, criterion, optim_scheduler_ft, num_epochs=25)



.. code-block:: python


    evaluate_model(model)



ConvNet as fixed feature extractor
----------------------------------

Here, we need to freeze all the network except the final layer. We need
to set ``requires_grad == False`` to freeze the parameters so that the
gradients are not computed in ``backward()``.

You can read more about this in documentation
`here <http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__.




.. code-block:: python


    model = torchvision.models.resnet18(pretrained=True)
    for param in model.parameters():
        param.requires_grad = False

    # Parameters of newly constructed modules have requires_grad=True by default
    model.fc = nn.Linear(512, 100)

    if use_gpu:
        model = model.cuda()



Let's write ``optim_scheduler``. We will use previous lr scheduler. Also
we need to optimize only the parameters of final FC layer.




.. code-block:: python


    def optim_scheduler_conv(model, epoch, init_lr=0.001, lr_decay_epoch=7):
        lr = init_lr * (0.1**(epoch // lr_decay_epoch))

        if epoch % lr_decay_epoch == 0:
            print('LR is set to {}'.format(lr))

        optimizer = optim.SGD(model.fc.parameters(), lr=lr, momentum=0.9)
        return optimizer



Train and evaluate:

On CPU this will take about half the time compared to previous scenario.
This is expected as gradients don't need to be computed for most of the
network. However, forward does need to be computed.




.. code-block:: python


    model = train_model(model, criterion, optim_scheduler_conv)



.. code-block:: python


    evaluate_model(model)

**Total running time of the script:** ( 0 minutes  0.000 seconds)



.. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: transfer_learning.py <transfer_learning.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: transfer_learning.ipynb <transfer_learning.ipynb>`

.. rst-class:: sphx-glr-signature

    `Generated by Sphinx-Gallery <http://sphinx-gallery.readthedocs.io>`_
