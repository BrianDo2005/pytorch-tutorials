

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-47062272-3']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Transfer Learning tutorial &mdash; PyTorch Tutorials  documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="PyTorch Tutorials  documentation" href="../index.html"/>
        <link rel="next" title="Reinforcement Learing (DQN) tutorial" href="reinforcement_q_learning_tutorial.html"/>
        <link rel="prev" title="Multi-GPU examples" href="torchies_parallelism_tutorial.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> PyTorch Tutorials
          

          
            
            <img src="../_static/pytorch-logo-dark.svg" class="logo" />
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="deep_learning_tutorial.html">Deep Learning with PyTorch: A 60 Minute Blitz</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tensor_tutorial.html">What is PyTorch?</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tensor_tutorial.html#getting-started">Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tensor_tutorial.html#tensors">Tensors</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensor_tutorial.html#operations">Operations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tensor_tutorial.html#numpy-bridge">Numpy Bridge</a><ul>
<li class="toctree-l4"><a class="reference internal" href="tensor_tutorial.html#converting-torch-tensor-to-numpy-array">Converting torch Tensor to numpy Array</a></li>
<li class="toctree-l4"><a class="reference internal" href="tensor_tutorial.html#converting-numpy-array-to-torch-tensor">Converting numpy Array to torch Tensor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tensor_tutorial.html#cuda-tensors">CUDA Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="autograd_tutorial.html">Autograd: automatic differentiation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="autograd_tutorial.html#variable">Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="autograd_tutorial.html#gradients">Gradients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="neural_networks_tutorial.html">Neural Networks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="neural_networks_tutorial.html#define-the-network">Define the network</a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_networks_tutorial.html#loss-function">Loss Function</a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_networks_tutorial.html#backprop">Backprop</a></li>
<li class="toctree-l3"><a class="reference internal" href="neural_networks_tutorial.html#update-the-weights">Update the weights</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cifar10_tutorial.html">Training a classifier</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cifar10_tutorial.html#what-about-data">What about data?</a></li>
<li class="toctree-l3"><a class="reference internal" href="cifar10_tutorial.html#training-an-image-classifier">Training an image classifier</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cifar10_tutorial.html#loading-and-normalizing-cifar10">1. Loading and normalizing CIFAR10</a></li>
<li class="toctree-l4"><a class="reference internal" href="cifar10_tutorial.html#define-a-convolution-neural-network">2. Define a Convolution Neural Network</a></li>
<li class="toctree-l4"><a class="reference internal" href="cifar10_tutorial.html#define-a-loss-function-and-optimizer">3. Define a Loss function and optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="cifar10_tutorial.html#train-the-network">4. Train the network</a></li>
<li class="toctree-l4"><a class="reference internal" href="cifar10_tutorial.html#test-the-network-on-the-test-data">5. Test the network on the test data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cifar10_tutorial.html#training-on-gpu">Training on GPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="cifar10_tutorial.html#where-do-i-go-next">Where do I go next?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="former_torchies_tutorial.html">PyTorch for former Torch users</a><ul>
<li class="toctree-l2"><a class="reference internal" href="torchies_tensor_tutorial.html">Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torchies_tensor_tutorial.html#inplace-out-of-place">Inplace / Out-of-place</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchies_tensor_tutorial.html#zero-indexing">Zero Indexing</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchies_tensor_tutorial.html#no-camel-casing">No camel casing</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchies_tensor_tutorial.html#numpy-bridge">Numpy Bridge</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torchies_tensor_tutorial.html#converting-torch-tensor-to-numpy-array">Converting torch Tensor to numpy Array</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchies_tensor_tutorial.html#converting-numpy-array-to-torch-tensor">Converting numpy Array to torch Tensor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torchies_tensor_tutorial.html#cuda-tensors">CUDA Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torchies_autograd_tutorial.html">Autograd</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torchies_autograd_tutorial.html#variable">Variable</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchies_autograd_tutorial.html#gradients">Gradients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torchies_nn_tutorial.html">nn package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torchies_nn_tutorial.html#example-1-convnet">Example 1: ConvNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchies_nn_tutorial.html#forward-and-backward-function-hooks">Forward and Backward Function Hooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchies_nn_tutorial.html#example-2-recurrent-net">Example 2: Recurrent Net</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torchies_parallelism_tutorial.html">Multi-GPU examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torchies_parallelism_tutorial.html#dataparallel">DataParallel</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchies_parallelism_tutorial.html#part-of-the-model-on-cpu-and-part-on-the-gpu">Part of the model on CPU and part on the GPU</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Transfer Learning tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#load-data">Load Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#visualize-a-few-images">Visualize a few images</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#training-the-model">Training the model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#visualizing-the-model-predictions">Visualizing the model predictions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#finetuning-the-convnet">Finetuning the convnet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#train-and-evaluate">Train and evaluate</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#convnet-as-fixed-feature-extractor">ConvNet as fixed feature extractor</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#id1">Train and evaluate</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="reinforcement_q_learning_tutorial.html">Reinforcement Learing (DQN) tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="reinforcement_q_learning_tutorial.html#replay-memory">Replay Memory</a></li>
<li class="toctree-l2"><a class="reference internal" href="reinforcement_q_learning_tutorial.html#dqn-algorithm">DQN algorithm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="reinforcement_q_learning_tutorial.html#q-network">Q-network</a></li>
<li class="toctree-l3"><a class="reference internal" href="reinforcement_q_learning_tutorial.html#input-extraction">Input extraction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="reinforcement_q_learning_tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="reinforcement_q_learning_tutorial.html#hyperparameters-and-utilities">Hyperparameters and utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="reinforcement_q_learning_tutorial.html#training-loop">Training loop</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="numpy_extensions_tutorial.html">Creating extensions using numpy and scipy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="numpy_extensions_tutorial.html#parameter-less-example">Parameter-less example</a></li>
<li class="toctree-l2"><a class="reference internal" href="numpy_extensions_tutorial.html#parametrized-example">Parametrized example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="c_extension.html">Custom C extensions for pytorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="c_extension.html#step-1-prepare-your-c-code">Step 1. prepare your C code</a></li>
<li class="toctree-l2"><a class="reference internal" href="c_extension.html#step-2-include-it-in-your-python-code">Step 2: Include it in your Python code</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">PyTorch With Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../jcjohnson_tutorial.html">Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../jcjohnson_tutorial.html#tensors">Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../jcjohnson_tutorial.html#warm-up-numpy">Warm-up: numpy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../jcjohnson_tutorial.html#pytorch-tensors">PyTorch: Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../jcjohnson_tutorial.html#autograd">Autograd</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../jcjohnson_tutorial.html#pytorch-variables-and-autograd">PyTorch: Variables and autograd</a></li>
<li class="toctree-l3"><a class="reference internal" href="../jcjohnson_tutorial.html#pytorch-defining-new-autograd-functions">PyTorch: Defining new autograd functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../jcjohnson_tutorial.html#tensorflow-static-graphs">TensorFlow: Static Graphs</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../jcjohnson_tutorial.html#nn-module"><cite>nn</cite> module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../jcjohnson_tutorial.html#pytorch-nn">PyTorch: nn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../jcjohnson_tutorial.html#pytorch-optim">PyTorch: optim</a></li>
<li class="toctree-l3"><a class="reference internal" href="../jcjohnson_tutorial.html#pytorch-custom-nn-modules">PyTorch: Custom nn Modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../jcjohnson_tutorial.html#pytorch-control-flow-weight-sharing">PyTorch: Control Flow + Weight Sharing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../jcjohnson_examples.html">Pytorch Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../jcjohnson_examples.html#tensor">Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../jcjohnson_examples.html#autograd">Autograd</a></li>
<li class="toctree-l2"><a class="reference internal" href="../jcjohnson_examples.html#nn-module"><cite>nn</cite> module</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Practical PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../practical-pytorch/char-rnn-classification-tutorial.html">Classifying Names with a Character-Level RNN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/char-rnn-classification-tutorial.html#preparing-the-data">Preparing the Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/char-rnn-classification-tutorial.html#turning-names-into-tensors">Turning Names into Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/char-rnn-classification-tutorial.html#creating-the-network">Creating the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/char-rnn-classification-tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/char-rnn-classification-tutorial.html#preparing-for-training">Preparing for Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/char-rnn-classification-tutorial.html#training-the-network">Training the Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/char-rnn-classification-tutorial.html#plotting-the-results">Plotting the Results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/char-rnn-classification-tutorial.html#evaluating-the-results">Evaluating the Results</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/char-rnn-classification-tutorial.html#running-on-user-input">Running on User Input</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/char-rnn-classification-tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../practical-pytorch/char-rnn-generation-tutorial.html">Generating Names with a Character-Level RNN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/char-rnn-generation-tutorial.html#preparing-the-data">Preparing the Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/char-rnn-generation-tutorial.html#creating-the-network">Creating the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/char-rnn-generation-tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/char-rnn-generation-tutorial.html#preparing-for-training">Preparing for Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/char-rnn-generation-tutorial.html#training-the-network">Training the Network</a></li>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/char-rnn-generation-tutorial.html#plotting-the-losses">Plotting the Losses</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/char-rnn-generation-tutorial.html#sampling-the-network">Sampling the Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/char-rnn-generation-tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html">Translation with a Sequence to Sequence Network and Attention</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#loading-data-files">Loading data files</a></li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#the-seq2seq-model">The Seq2Seq Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#the-encoder">The Encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#the-decoder">The Decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#simple-decoder">Simple Decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#attention-decoder">Attention Decoder</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#preparing-training-data">Preparing Training Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#training">Training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#plotting-results">Plotting results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#evaluation">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#training-and-evaluating">Training and Evaluating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../practical-pytorch/seq2seq-translation-tutorial.html#exercises">Exercises</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">PyTorch Tutorials</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li>Transfer Learning tutorial</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/tutorials/transfer_learning_tutorial.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="transfer-learning-tutorial">
<span id="sphx-glr-tutorials-transfer-learning-tutorial-py"></span><h1>Transfer Learning tutorial<a class="headerlink" href="#transfer-learning-tutorial" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial, you will learn how to train your network using
transfer learning. You can read more about the transfer learning at <a class="reference external" href="http://cs231n.github.io/transfer-learning/">cs231n
notes</a></p>
<p>Quoting this notes,</p>
<blockquote>
<div>In practice, very few people train an entire Convolutional Network
from scratch (with random initialization), because it is relatively
rare to have a dataset of sufficient size. Instead, it is common to
pretrain a ConvNet on a very large dataset (e.g. ImageNet, which
contains 1.2 million images with 1000 categories), and then use the
ConvNet either as an initialization or a fixed feature extractor for
the task of interest.</div></blockquote>
<p>These two major transfer learning scenarios looks as follows:</p>
<ul class="simple">
<li><strong>Finetuning the convnet</strong>: Instead of random initializaion, we
initialize the network with a pretrained network, like the one that is
trained on imagenet 1000 dataset. Rest of the training looks as
usual.</li>
<li><strong>ConvNet as fixed feature extractor</strong>: Here, we will freeze the weights
for all of the network except that of the final fully connected
layer. This last fully connected layer is replaced with a new one
with random weights and only this layer is trained.</li>
</ul>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># License: BSD</span>
<span class="c1"># Author: Sasank Chilamkurthy</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="kn">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="kn">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">os</span>
</pre></div>
</div>
<div class="section" id="load-data">
<h2>Load Data<a class="headerlink" href="#load-data" title="Permalink to this headline">¶</a></h2>
<p>We will use torchvision and torch.utils.data packages for loading the
data.</p>
<p>The problem we&#8217;re going to solve today is to train a model to classify
<strong>ants</strong> and <strong>bees</strong>. We have about 120 training images each for ants and bees.
There are 75 validation images for each class. Usually, this is a very
small dataset to generalize upon, if trained from scratch. Since we
are using transfer learning, we should be able to generalize reasonably
well.</p>
<p>This dataset is a very small subset of imagenet. Download the data from
<a class="reference external" href="https://github.com/chsasank/pytorch-tutorials/raw/master/tutorial_source/hymenoptera_data.zip">here</a>
and extract it to the current directory.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># Data augmentation and normalization for training</span>
<span class="c1"># Just normalization for validation</span>
<span class="n">data_transforms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomSizedCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">]),</span>
    <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Scale</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">]),</span>
<span class="p">}</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;hymenoptera_data&#39;</span>
<span class="n">dsets</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="n">data_transforms</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
         <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">dset_loaders</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dsets</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                               <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">dset_sizes</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">dsets</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">dset_classes</span> <span class="o">=</span> <span class="n">dsets</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">classes</span>

<span class="n">use_gpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
</pre></div>
</div>
<div class="section" id="visualize-a-few-images">
<h3>Visualize a few images<a class="headerlink" href="#visualize-a-few-images" title="Permalink to this headline">¶</a></h3>
<p>Let&#8217;s visualize a few training images so as to understand the data
augmentations.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">])</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">std</span> <span class="o">*</span> <span class="n">inp</span> <span class="o">+</span> <span class="n">mean</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>


<span class="c1"># Get a batch of training data</span>
<span class="n">inputs</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dset_loaders</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]))</span>

<span class="c1"># Make a grid from batch</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="n">imshow</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">([</span><span class="n">dset_classes</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/sphx_glr_transfer_learning_tutorial_001.png" class="align-center" src="../_images/sphx_glr_transfer_learning_tutorial_001.png" />
</div>
</div>
<div class="section" id="training-the-model">
<h2>Training the model<a class="headerlink" href="#training-the-model" title="Permalink to this headline">¶</a></h2>
<p>Now, let&#8217;s write a general function to train a model. Here, we will
illustrate:</p>
<ul class="simple">
<li>Scheduling the learning rate</li>
<li>Saving (deep copying) the best model</li>
</ul>
<p>In the following, <code class="docutils literal"><span class="pre">optim_scheduler</span></code> is a function which returns an <code class="docutils literal"><span class="pre">optim.SGD</span></code>
object when called as <code class="docutils literal"><span class="pre">optim_scheduler(model,</span> <span class="pre">epoch)</span></code>. This is useful
when we want to change the learning rate or restrict the parameters we
want to optimize.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optim_scheduler</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span>
    <span class="n">since</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">best_model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Epoch {}/{}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>

        <span class="c1"># Each epoch has a training and validation phase</span>
        <span class="k">for</span> <span class="n">phase</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim_scheduler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">running_corrects</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Iterate over data.</span>
            <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">dset_loaders</span><span class="p">[</span><span class="n">phase</span><span class="p">]:</span>
                <span class="c1"># get the inputs</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>

                <span class="c1"># wrap them in Variable</span>
                <span class="k">if</span> <span class="n">use_gpu</span><span class="p">:</span>
                    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">cuda</span><span class="p">()),</span> \
                        <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

                <span class="c1"># zero the parameter gradients</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># forward</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

                <span class="c1"># backward + optimize only if in training phase</span>
                <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># statistics</span>
                <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">running_corrects</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="n">dset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span>
            <span class="n">epoch_acc</span> <span class="o">=</span> <span class="n">running_corrects</span> <span class="o">/</span> <span class="n">dset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span>

            <span class="k">print</span><span class="p">(</span><span class="s1">&#39;{} Loss: {:.4f} Acc: {:.4f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">phase</span><span class="p">,</span> <span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">))</span>

            <span class="c1"># deep copy the model</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;val&#39;</span> <span class="ow">and</span> <span class="n">epoch_acc</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
                <span class="n">best_acc</span> <span class="o">=</span> <span class="n">epoch_acc</span>
                <span class="n">best_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="k">print</span><span class="p">()</span>

    <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">since</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Training complete in {:.0f}m {:.0f}s&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">time_elapsed</span> <span class="o">//</span> <span class="mi">60</span><span class="p">,</span> <span class="n">time_elapsed</span> <span class="o">%</span> <span class="mi">60</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Best val Acc: {:4f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_acc</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">best_model</span>
</pre></div>
</div>
<div class="section" id="visualizing-the-model-predictions">
<h3>Visualizing the model predictions<a class="headerlink" href="#visualizing-the-model-predictions" title="Permalink to this headline">¶</a></h3>
<p>Generic function to display predictions for a few images</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualize_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dset_loaders</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]):</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
        <span class="k">if</span> <span class="n">use_gpu</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">cuda</span><span class="p">()),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">Variable</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>


        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">imshow</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;pred: {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dset_classes</span><span class="p">[</span><span class="n">labels</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]]))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">num_images</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">break</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="finetuning-the-convnet">
<h2>Finetuning the convnet<a class="headerlink" href="#finetuning-the-convnet" title="Permalink to this headline">¶</a></h2>
<p>First, let&#8217;s create our learning rate scheduler. We will exponentially
decrease the learning rate once every few epochs.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">optim_scheduler_ft</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">init_lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">lr_decay_epoch</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">init_lr</span> <span class="o">*</span> <span class="p">(</span><span class="mf">0.1</span><span class="o">**</span><span class="p">(</span><span class="n">epoch</span> <span class="o">//</span> <span class="n">lr_decay_epoch</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">lr_decay_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;LR is set to {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="p">))</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">optimizer</span>
</pre></div>
</div>
<p>Load a pretrained model and reset final fully connected layer.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="k">if</span> <span class="n">use_gpu</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
<div class="section" id="train-and-evaluate">
<h3>Train and evaluate<a class="headerlink" href="#train-and-evaluate" title="Permalink to this headline">¶</a></h3>
<p>It should take around 15-25 min on CPU. On GPU though, it takes less than a
minute.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optim_scheduler_ft</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">LR</span> <span class="ow">is</span> <span class="nb">set</span> <span class="n">to</span> <span class="mf">0.001</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1440</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7049</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1385</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7582</span>

<span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1093</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8279</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1162</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8105</span>

<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0993</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8402</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1310</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7516</span>

<span class="n">Epoch</span> <span class="mi">3</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1077</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8279</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1393</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8039</span>

<span class="n">Epoch</span> <span class="mi">4</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1301</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8238</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1336</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7778</span>

<span class="n">Epoch</span> <span class="mi">5</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1382</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8033</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2405</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7190</span>

<span class="n">Epoch</span> <span class="mi">6</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1047</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8279</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1684</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7843</span>

<span class="n">Epoch</span> <span class="mi">7</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">LR</span> <span class="ow">is</span> <span class="nb">set</span> <span class="n">to</span> <span class="mf">0.0001</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1101</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8361</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1159</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8105</span>

<span class="n">Epoch</span> <span class="mi">8</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0925</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8238</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1456</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7582</span>

<span class="n">Epoch</span> <span class="mi">9</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0636</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8811</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0867</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8366</span>

<span class="n">Epoch</span> <span class="mi">10</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1027</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8033</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1201</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8235</span>

<span class="n">Epoch</span> <span class="mi">11</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0909</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8279</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1013</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8431</span>

<span class="n">Epoch</span> <span class="mi">12</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0844</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8648</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1101</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8105</span>

<span class="n">Epoch</span> <span class="mi">13</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0903</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8566</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1231</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7647</span>

<span class="n">Epoch</span> <span class="mi">14</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">LR</span> <span class="ow">is</span> <span class="nb">set</span> <span class="n">to</span> <span class="mf">1.0000000000000003e-05</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0562</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8975</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1090</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7843</span>

<span class="n">Epoch</span> <span class="mi">15</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0678</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8770</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1196</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7908</span>

<span class="n">Epoch</span> <span class="mi">16</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0834</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8484</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1057</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8235</span>

<span class="n">Epoch</span> <span class="mi">17</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0711</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8770</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1374</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8105</span>

<span class="n">Epoch</span> <span class="mi">18</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0743</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8730</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1000</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8497</span>

<span class="n">Epoch</span> <span class="mi">19</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0763</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8648</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1119</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8235</span>

<span class="n">Epoch</span> <span class="mi">20</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0785</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8607</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1189</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8039</span>

<span class="n">Epoch</span> <span class="mi">21</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">LR</span> <span class="ow">is</span> <span class="nb">set</span> <span class="n">to</span> <span class="mf">1.0000000000000002e-06</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0888</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8648</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1213</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7843</span>

<span class="n">Epoch</span> <span class="mi">22</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0634</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8770</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1118</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8039</span>

<span class="n">Epoch</span> <span class="mi">23</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0664</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8770</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1032</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7974</span>

<span class="n">Epoch</span> <span class="mi">24</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0648</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9098</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0985</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8301</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">0</span><span class="n">m</span> <span class="mi">40</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.849673</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">visualize_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_transfer_learning_tutorial_002.png"><img alt="../_images/sphx_glr_transfer_learning_tutorial_002.png" src="../_images/sphx_glr_transfer_learning_tutorial_002.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_transfer_learning_tutorial_003.png"><img alt="../_images/sphx_glr_transfer_learning_tutorial_003.png" src="../_images/sphx_glr_transfer_learning_tutorial_003.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_transfer_learning_tutorial_004.png"><img alt="../_images/sphx_glr_transfer_learning_tutorial_004.png" src="../_images/sphx_glr_transfer_learning_tutorial_004.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_transfer_learning_tutorial_005.png"><img alt="../_images/sphx_glr_transfer_learning_tutorial_005.png" src="../_images/sphx_glr_transfer_learning_tutorial_005.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_transfer_learning_tutorial_006.png"><img alt="../_images/sphx_glr_transfer_learning_tutorial_006.png" src="../_images/sphx_glr_transfer_learning_tutorial_006.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
</ul>
</div>
</div>
<div class="section" id="convnet-as-fixed-feature-extractor">
<h2>ConvNet as fixed feature extractor<a class="headerlink" href="#convnet-as-fixed-feature-extractor" title="Permalink to this headline">¶</a></h2>
<p>Here, we need to freeze all the network except the final layer. We need
to set <code class="docutils literal"><span class="pre">requires_grad</span> <span class="pre">==</span> <span class="pre">False</span></code> to freeze the parameters so that the
gradients are not computed in <code class="docutils literal"><span class="pre">backward()</span></code>.</p>
<p>You can read more about this in the documentation
<a class="reference external" href="http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward">here</a>.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">False</span>

<span class="c1"># Parameters of newly constructed modules have requires_grad=True by default</span>
<span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="k">if</span> <span class="n">use_gpu</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</pre></div>
</div>
<p>Let&#8217;s write <code class="docutils literal"><span class="pre">optim_scheduler</span></code>. We will use previous lr scheduler. Also
we need to optimize only the parameters of final FC layer.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">optim_scheduler_conv</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">init_lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">lr_decay_epoch</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">init_lr</span> <span class="o">*</span> <span class="p">(</span><span class="mf">0.1</span><span class="o">**</span><span class="p">(</span><span class="n">epoch</span> <span class="o">//</span> <span class="n">lr_decay_epoch</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="n">lr_decay_epoch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;LR is set to {}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="p">))</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">optimizer</span>
</pre></div>
</div>
<div class="section" id="id1">
<h3>Train and evaluate<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>On CPU this will take about half the time compared to previous scenario.
This is expected as gradients don&#8217;t need to be computed for most of the
network. However, forward does need to be computed.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optim_scheduler_conv</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-default"><div class="highlight"><pre><span></span><span class="n">Epoch</span> <span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">LR</span> <span class="ow">is</span> <span class="nb">set</span> <span class="n">to</span> <span class="mf">0.001</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.2802</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.5697</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1284</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7582</span>

<span class="n">Epoch</span> <span class="mi">1</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1423</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7254</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0970</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8431</span>

<span class="n">Epoch</span> <span class="mi">2</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1103</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7910</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1480</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7647</span>

<span class="n">Epoch</span> <span class="mi">3</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0956</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8197</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1581</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.6993</span>

<span class="n">Epoch</span> <span class="mi">4</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1087</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8156</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1642</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7451</span>

<span class="n">Epoch</span> <span class="mi">5</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0991</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8115</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0839</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9020</span>

<span class="n">Epoch</span> <span class="mi">6</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1173</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7787</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1336</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7908</span>

<span class="n">Epoch</span> <span class="mi">7</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">LR</span> <span class="ow">is</span> <span class="nb">set</span> <span class="n">to</span> <span class="mf">0.0001</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1130</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8074</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0868</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8627</span>

<span class="n">Epoch</span> <span class="mi">8</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0652</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8852</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0979</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8627</span>

<span class="n">Epoch</span> <span class="mi">9</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0798</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8484</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0856</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8562</span>

<span class="n">Epoch</span> <span class="mi">10</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0942</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8443</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1157</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7974</span>

<span class="n">Epoch</span> <span class="mi">11</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0911</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8402</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1150</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7778</span>

<span class="n">Epoch</span> <span class="mi">12</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1106</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7992</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0829</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8497</span>

<span class="n">Epoch</span> <span class="mi">13</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1115</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8197</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1218</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7712</span>

<span class="n">Epoch</span> <span class="mi">14</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">LR</span> <span class="ow">is</span> <span class="nb">set</span> <span class="n">to</span> <span class="mf">1.0000000000000003e-05</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0683</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8975</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0950</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8758</span>

<span class="n">Epoch</span> <span class="mi">15</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0817</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8361</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0954</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8627</span>

<span class="n">Epoch</span> <span class="mi">16</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0724</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8975</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0793</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8954</span>

<span class="n">Epoch</span> <span class="mi">17</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0722</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8730</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0892</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8562</span>

<span class="n">Epoch</span> <span class="mi">18</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0782</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8484</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0793</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8627</span>

<span class="n">Epoch</span> <span class="mi">19</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0728</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8607</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1068</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8105</span>

<span class="n">Epoch</span> <span class="mi">20</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1002</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8361</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0671</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.9020</span>

<span class="n">Epoch</span> <span class="mi">21</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">LR</span> <span class="ow">is</span> <span class="nb">set</span> <span class="n">to</span> <span class="mf">1.0000000000000002e-06</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0950</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8115</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0806</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8431</span>

<span class="n">Epoch</span> <span class="mi">22</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0965</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8320</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1113</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8105</span>

<span class="n">Epoch</span> <span class="mi">23</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0861</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8607</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0970</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.7974</span>

<span class="n">Epoch</span> <span class="mi">24</span><span class="o">/</span><span class="mi">24</span>
<span class="o">----------</span>
<span class="n">train</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.0742</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8852</span>
<span class="n">val</span> <span class="n">Loss</span><span class="p">:</span> <span class="mf">0.1019</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.8431</span>

<span class="n">Training</span> <span class="n">complete</span> <span class="ow">in</span> <span class="mi">0</span><span class="n">m</span> <span class="mi">24</span><span class="n">s</span>
<span class="n">Best</span> <span class="n">val</span> <span class="n">Acc</span><span class="p">:</span> <span class="mf">0.901961</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">visualize_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_transfer_learning_tutorial_007.png"><img alt="../_images/sphx_glr_transfer_learning_tutorial_007.png" src="../_images/sphx_glr_transfer_learning_tutorial_007.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_transfer_learning_tutorial_008.png"><img alt="../_images/sphx_glr_transfer_learning_tutorial_008.png" src="../_images/sphx_glr_transfer_learning_tutorial_008.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_transfer_learning_tutorial_009.png"><img alt="../_images/sphx_glr_transfer_learning_tutorial_009.png" src="../_images/sphx_glr_transfer_learning_tutorial_009.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_transfer_learning_tutorial_010.png"><img alt="../_images/sphx_glr_transfer_learning_tutorial_010.png" src="../_images/sphx_glr_transfer_learning_tutorial_010.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../_images/sphx_glr_transfer_learning_tutorial_011.png"><img alt="../_images/sphx_glr_transfer_learning_tutorial_011.png" src="../_images/sphx_glr_transfer_learning_tutorial_011.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
</ul>
<p><strong>Total running time of the script:</strong> ( 1 minutes  7.700 seconds)</p>
<div class="sphx-glr-footer docutils container">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/transfer_learning_tutorial.py" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">transfer_learning_tutorial.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" href="../_downloads/transfer_learning_tutorial.ipynb" download=""><code class="xref download docutils literal"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">transfer_learning_tutorial.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="http://sphinx-gallery.readthedocs.io">Generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="reinforcement_q_learning_tutorial.html" class="btn btn-neutral float-right" title="Reinforcement Learing (DQN) tutorial" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="torchies_parallelism_tutorial.html" class="btn btn-neutral" title="Multi-GPU examples" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, PyTorch.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>